

##
## Introduction to Generative AI 
##

https://www.cloudskillsboost.google/course_sessions/11483366/video/434966


    +--------------------------+
    |           AI             |
    |   +------------------+   |
    |   |       ML         |   | 
    |   |   +----------+   |   |
    |   |   |   Deep   |   |   |
    |   |   | Learning |   |   |
    |   |   +----------+   |   |
    |   |                  |   | 
    |   +------------------+   |
    |                          |
    +--------------------------+



ML Model trained from Data
    - without explicit programming
    - supervised
            - input data 
            - model  <------------------------+
            - predict output                  |
            - compare to training dataset     |
            - update model (reduce error)  ---+
    - unsupervised
            - input data 
            - model  
            - generated example  



Deep Learning uses Artifical Neural Networks
    - interconnected nodes / neurons



    input         hidden      output
    layer         layer        layer

      x
      x            +
      x            +             o
      x            +             o
      x            +             o
      x            +             o
      x            +
      x


- Generative AI subset of deep learning
- LLM subset of deep learning

Deep Learning Model Type:
    - Generative
        - generates new data similar to trained data
        - understands distribution of data
        - predict next word in sequence

    - Discriminative
        - classify or predict
        - trained on labled data
        - learns relationship between features of data points and labels



    Not Gen AI, output is 
        - number
        - discrete
        - class
        - probability

    Is Gen AI, output is 
        - Natural Language
        - Image
        - Audio

    ex. PaLM : Pathways Language Model 
        LaMDA: Language Model for Dialogue Applications


Generative AI: 
    - type of AI that create new content based on what it has learned from existing content
    - process of learning from existing content is training 
        - results in creation of statistical model
    - given a prompt, GenAI uses statistical model to predict what response might be

Generative Language Models learn about patterns in language thru training data 
    - pattern mathing system 


Gen Ai derived from Transformers:
    - Transformer model consists of 
        - encoder: encodes input sequence / passes to decoder
        - decoder: learns to decode the representation for a task 

Hallucinations: words / phrases generated by model that are non-sensical / incorrect

prompt: piece of text givent to LLM as input
            - can be used to control output of model


model types:
    text-to-text
    text-to-image
    text-to-video
    text-to-3D
    text-to-task

ex. Vertex AI: model garden that includes foundation models
    Language: PaLM API for Chat
              PaLM API for Text
              BERT
    Vision:   Stable Diffustion v1-5
              BLIP image captioning 
              CLIP 
              OWL, etc.


Model Garden Task Specific Models 

    Language: Extraction: 
                    - Syntax Analysis
              Classification: 
                    - Entity Analysis
                    - Content Classification
                    - Sentiment Analysis
                    - Entity Sentiment Analysis

    Vision:   Classification: 
                    - Object detector
              Detection:
                    - Occupancy analytics
                    - Person / Vehicle detector
                    - PPE detector
                    - Person blur


Colab: Google's free Jupyter

GenAI Studio: create and deploy GenAI Models 
            - Language / Vision
            - Library of pre-trained models
            - tool to fine tunemodels
            - AI App Builder
                    - create gen AI apps wihout writing code


- Vertext AI Search and Conversation

- MakerSuite: prototype apps using PaLM API
    - model training tool
    - model deployment tool
    - model monitoring tool


## Resources: 



All Readings: Introduction to Generative AI (G-GENAI-I)

[[ Here are the assembled readings on generative AI: ]]

● Ask a Techspert: What is generative AI?
https://blog.google/inside-google/googlers/ask-a-techspert/what-is-generative-ai/

● Build new generative AI powered search & conversational experiences with Gen App
Builder:
https://cloud.google.com/blog/products/ai-machine-learning/create-generative-apps-in-minutes-with-gen-app-builder

● What is generative AI?
https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-generative-ai

● Google Research, 2022 & beyond: Generative models:
https://ai.googleblog.com/2023/01/google-research-2022-beyond-language.html#GenerativeModels


● Building the most open and innovative AI ecosystem:
https://cloud.google.com/blog/products/ai-machine-learning/building-an-open-generative-ai-partner-ecosystem


● Generative AI is here. Who Should Control It?
https://www.nytimes.com/2022/10/21/podcasts/hard-fork-generative-artificial-intelligence.html


● Stanford U & Google’s Generative Agents Produce Believable Proxies of Human
Behaviors:
https://syncedreview.com/2023/04/12/stanford-u-googles-generative-agents-produce-believable-proxies-of-human-behaviours/

● Generative AI: Perspectives from Stanford HAI:
https://hai.stanford.edu/sites/default/files/2023-03/Generative_AI_HAI_Perspectives

● Generative AI at Work:
https://www.nber.org/system/files/working_papers/w31161/w31161.pdf

● The future of generative AI is niche, not generalized:
https://www.technologyreview.com/2023/04/27/1072102/the-future-of-generative-ai-is-niche-not-generalized/


● The implications of Generative AI for businesses:
https://www2.deloitte.com/us/en/pages/consulting/articles/generative-artificial-intelligence.html

● Proactive Risk Management in Generative AI:
https://www2.deloitte.com/us/en/pages/consulting/articles/responsible-use-of-generative-ai.html

● How Generative AI Is Changing Creative Work:
https://hbr.org/2022/11/how-generative-ai-is-changing-creative-work


[[ Here are the assembled readings on large language models: ]]

● NLP's ImageNet moment has arrived: https://thegradient.pub/nlp-imagenet/

● LaMDA: our breakthrough conversation technology:
https://blog.google/technology/ai/lamda/

● Language Models are Few-Shot Learners:
https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf


● PaLM-E: An embodied multimodal language model:
https://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html

● PaLM API & MakerSuite: an approachable way to start prototyping and building
generative AI applications:
https://developers.googleblog.com/2023/03/announcing-palm-api-and-makersuite.html

● The Power of Scale for Parameter-Efficient Prompt Tuning:
https://arxiv.org/pdf/2104.08691.pdf

● Google Research, 2022 & beyond: Language models:
https://ai.googleblog.com/2023/01/google-research-2022-beyond-language.html/LanguageModels


● Solving a machine-learning mystery:
https://news.mit.edu/2023/large-language-models-in-context-learning-0207

[[ Additional Resources: ]]

● Attention is All You Need: https://research.google/pubs/pub46201/

● Transformer: A Novel Neural Network Architecture for Language Understanding:
https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html

● Transformer on Wikipedia:
https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)#:~:text=Transformers%20were%20introduced%20in%202017,allowing%20training%20on%20larger%20datasets.

● What is Temperature in NLP? https://lukesalamone.github.io/posts/what-is-temperature/

● Model Garden: https://cloud.google.com/model-garden

● Auto-generated Summaries in Google Docs:
https://ai.googleblog.com/2022/03/auto-generated-summaries-in-google-docs.html




#########################################################################################################
##
## ChatGPT for Everyone	
##
#########################################################################################################

ChatGPT for Everyone	
https://learnprompting.thinkific.com/courses/take/ChatGPT-for-Everyone/lessons/52250248-introduction


ChatGPT: Conversational Generative AI
    - Generative Pre-Trained Transformer

prompt:  question of set of instructions

# Basics of Prompt Engineering
    - Instruction: main objective or question
    - Context: text / data provided
    - Role: having ChatGPT assume a role to execute for the answer (act as a personal assitent, rust developer, etc.)
    - Format Instructions: Step-by-Step DIY Guide, put summary data in a markdown table 
    - Few-Shot Prompting: Show examples of what to do i.e. how paragraphs were summarized in the past 

# Improving Prompts
    - "Say it in the style of XYZ"
    Prompt Engineering:  Refine prompt over time >> Conversational Prompt Engineering


# Advanced ChatGPT Interface

    - bottom left > account name
    - click > menu: Custom Instructions 
            - allows for additional context
            - shape how ChatGPT responds:
                - What would you like ChatGPT to know about you to proivde better responses (location, work, hobbies, goals, etc)
                - How would you like ChatGPT to respond (how formal or casual, how long / short, how addressed, etc.)

    - history section on left
        - each chat saved
        - NOTE: Chats will be used to train ChatGPT
                - To Turn Off  Account > Settings > Data Controls > Chat History & Training [Off]

    - Share Chat: Top Right > Copy Link 

# ChatGPT's Advanced Features on ChatGPT Plus Accounts
    - Using ChatGPT Vision Capabilities
            - upload image and ask questions about it (ChatGPT 4)
    - Access the Internet
    - Advanced Data Analytics
            - upload a pdf, xls and analyze 
    - DALL-E 3

# Limitations
    - Hallucinations: Doesn't now correct answer but answers anyway
        ex. Which country is bigger, Nigeria or Chad ? 

    - Citing sources:  ChatGPT can make up sources 
        - use proper context

# Bias
    - Training data has been trained on biased data 
        - Prompt to "not be biased" and fine tune 

# Data Privacy
    - ChatGPT records prompts
        - turn off as above
    - ChatGPT does not record or improve model with data from Enterprise Plan

Certificate of completion:
https://learnprompting.thinkific.com/account/certificates
https://learnprompting.thinkific.com/certificates/djnxpzyykn





#########################################################################################################
##
## Generative AI for Everyone	
##
#########################################################################################################

https://www.coursera.org/learn/generative-ai-for-everyone/home/week/1

[week 1]
- AI is a set of tools 
    - Supervised learning (labeling things)
    - Unsupervised learning 
    - Reinforcement learning 
    - Generative AI

Supervised learning  (labeling things)
    Input   -> Output


    Input (A)           Output (B)             |   Application
    -------------------------------------------|----------------------------------
     Email                 Spam?  (0/1)        |  Spam filtering
     Ad, user info         Click? (0/1)        |  Online advertising
     Image, radar info   Position other cars   |  Self-driving car
     x-ray image           Diagnosis           |  Healthcare
     image of phone        Defect? (0/1)       |  Visual inspection
     audio recording       Text transcript     |  Speech recognition
     restaurant reviews    Sentiment (neg/pos) |  Reputation monitoring

2010 - 2020: Large scale supervised learning
    Small AI models:  larger data didn't not result in better performance
    Large AI models:  larger data DID result in better performance

    i.e. Let's build large models and feed them ALOT of data
            - pathway to Generative AI


How LLMs work: 
    - LLMs are built by using supervised learning (A -> B) to repeatedly predict the next word. 

        ex. My favorite food is a bagel with cream cheese
    Input (A)  [prompt]                       | Output (B)  [response]
    ----------------------------------------- | ----------------------------
    My favorite food is a                     |  bagel
    My favorite food is a bagel               |  with 
    My favorite food is a bagel with          |  cream  
    My favorite food is a bagel with cream    |  cheese 

    When train an AI system on hundreds of billions of words, get an LLM


Uses for LLMs:
    - writing / brainstorming
    - reading / read and summerize text (emails, etc.)
    - chatting / chatbots
    web  vs.  app 

Gen AI Applications:
  Text:
    - brainstorming
    - writing emails / articles
    - translations (Priate English)

  Reading:
    - proofreading
    - summary
    - email analysis 
    - sentiment / reputation monitoring
    NOTE: refine prompts with additional information

  Chatting:
    - customer service


LLMs: Can vs. Can't Do
Can:
    - can a college grad execute the prompt ?  (guideline)
            - add data to complete the task
    - knowledge cutoffs, LLMs training stops at a certain date
    - Hallucinations: ask about well known people and you may get dubious quotes
    - input / output length is limited
    - Does not work well with structured (tabular) data (used supervised data for this)
    - Works best with unstructured data 
    - Bias / Toxicity


Tips for prompting:

    - Be detailed and specific 
            - Give enough context to complete the task
            - describe taks in detail

    - Guide the model to think through its answer
            - give steps thru the answer 
                    Brainstorm 5 names for a new baby toy.
                    Step 1: Come up with 5 fun, joyful words that relate to human babies.
                    Step 2: For each word, come up with a rhyming name for a toy.
                    Step 3: Fore each toy name, add a fun relevant emoji.
            
    - Experiment and iterate
            - develop a process to iterate 
            - improve prompts

            Idea -----> Prompt -----> LLM Response  ----->  Refine --+
             ^-------------------------------------------------------+
                        (add more detail or detailed task)

Image Generation :

   Image Generation (diffusion model) 
        - learns from images on the Internet (via supervised learning)
        - take an image and then add "noise" to the image
            - teach model to take "noisy" image and generate less-noisy image ---+
                ^------------------------- REPEAT -------------------------------+ 
                NOTE: typically 100 steps for a diffusion model

        - image has text caption associated with it 
        - to generate new image 
            - image is pure noisy 
            - input prompt from user 
            - diffuse to lessy noisy image (repeat per above)


[week 2]
MAP LAST HERE
https://www.coursera.org/learn/generative-ai-for-everyone/lecture/LfGc4/using-generative-ai-in-software-applications



.